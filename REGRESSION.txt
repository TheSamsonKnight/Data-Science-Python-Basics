REGRESSION
============================================================================================================================================================================================================
-THE PROCESS OF PREDICTING A CONTINUOUS VALUE
-DEPENDENT VARIABLE Y: STATE/TARGET/FINAL GOAL STUDIED AND TRY TO PREDICT
-INDEPENDENT VARIABLE(ONE OR MORE) X: EXPLANATORY IS SEEN AS CAUSES OF THOSE STATES
-SIMPLE REGRESSION: WHEN ONE INDEPENDENT VARIABLE IS USED TO ESTIMATE A DEPENDENT VARIABLE
	-SIMPLE LINEAR REGRESSION: BASED ON NATURE OF RELATIONSHIP BETWEEN IND VS DEP
	-SIMPLE NON-LINEAR REGRESSION:
-MULTIPLE REGRESSION: WHEN MORE THAN ONE INDEPENDENT VARIABLE IS PRESENT
	-MULTIPLE LINEAR REGRESSION:
	-MULTIPLE NON-LINEAR REGRESSION:
-REGRESSION ALGORITHMS:
	ORDINAL		POISSON		FAST FOREST QUANTILE
	LINEAR		POLYNOMIAL	LASSO	STEPWISE	RIDGE
	BAYESIAN LINEAR		NEURAL NETWORK		DECISION FOREST
	BOOSTED DECISION TREE		K NEAREST NEIGHBORS
============================================================================================================================================================================================================
SIMPLE LINEAR REGRESSION

-APPROXIMATION OF A LINEAR MODEL USED TO DESCRIBE THE RELATIONSHIP BETWEEN TWO OR MORE VARIABLES
-ESTIMATES THE COEFFICIENTS OF THE LINE
-TWO VARIABLES
	DEPENDENT: SHOULD BE CONTINUOUS AND CANNOT BE A DISCRETE VALUE
	INDEPENDENT: CAN BE MEASURED CATEGORICAL OR CONTINUOUS MEASUREMENT SCALE
-LINEAR REGRESSION TOPOLOGY:
	SIMPLE LINEAR REGRESSION: WHEN ONE IND VARIABLE IS USED TO ESTIMATE A DEP VARIABLE
	MULITPLE LINEAR REGRESSION: WHEN ONE OR MORE IND VARIABLE IS PRESENT 

^
Y = Oo+O1X1
YHAT = DEP VARIABLE/THE PREDICTED VALUE(RESPONSE VARIABLE)
X1 = IND VARIABLE
Oo/O1 = PARAMETERS OF THE LINE THAT WE MUST ADJUST/COEFFICIENTS OF THE LINEAR EQUATION(FIT LINE)
	O1 = SLOPE/GRADIENT OF THE FITTIN LINE
	Oo = INTERCEPT 

-OBJECTIVE OF LINEAR REGRESSION IS TO MINIMIZE THE MSE EQUATION, FIND THE BEST PARAMETERS
-PROS OF LINEAR REGRESSION:
	-FAST
	-NO PARAMETER TUNING
	-EASY TO UNDERSTAND, HIGHLY INTERPRETABLE
============================================================================================================================================================================================================
MODEL EVALUATION IN REGRESSION MODELS

-THE GOAL OF REGRESSION IS TO BUILD A MODEL TO ACCURATELY PREDICT UNKNOWN CASES
-EVALUATION APPROACHES:
	TRAIN AND TEST ON THE SAME DATASET
		HIGH TRAINING ACCURACY, LOW OUT-OF-SAMPLE ACCURACY (OVERFITTING)
	TRAIN/TEST SPLIT
		MORE ACCURATE EVAL ON OUT-OF-SAMPLE
		HIGHLY DEPENDENT ON WHICH DATASETS THE DATA IS TRAINED AND TESTED
	K-FOLD CROSS-VALIDATION
		PERFORMS MULTIPLE TRAIN/TEST SPLITS USING SAME DATASET WHERE EACH SPLIT IS DIFFERENT, 		THE RESULT IS AVERAGED TO PRODUCED MORE CONSISTENT OUT-OF-SAMPLE ACCURACY
============================================================================================================================================================================================================
EVALUATION METRICS IN REGRESSION MODELS

-PROVIDE A KEY ROLE IN THE DEVELOPMENT OF A MODEL AS IT PROVIDES INSIGHT TO AREAS THAT REQ IMPROVEMENT
-ERROR OF A MODEL: MEASURE OF HOW FAR THE DATA IS FROM THE FITTED REGESSION LINE(ALGORITHM)
-MEAN ABSOLUTE ERROR: AVERAGE OF THE ABSOLUTE VALUE OF THE ERRORS
-MEAN SQUARED ERROR: AVERAGE OF THE SQUARED ERROR
	FOCUS IS GEARED MORE TOWARDS LARGE ERRORS
-ROOT MEAN SQUARED ERROR: THE SQUARE ROOT OF THE MSE
	INTERPRETABLE IN THE SAME UNITS AS THE RESPONSE VECTOR (Y UNITS)
-RELATIVE ABSOLUTE ERROR(RESIDUAL OF SUM OF SQUARE): Y BAR IS A MEAN VALUE OF Y, TAKES TOTAL ABSOLTE 	ERROR AND NORMALIZES IT 
-RELATIVE SQUARED ERROR: CALCULATES R-SQUARED
-R SQUARED: ACCURACY OF THE MODEL, HOW CLOSE DATA VALUES ARE TO THE FITTED REGRESSION LINE
	THE HIGHER THE VALUE, THE BETTER THE MODEL FITS THE DATA
============================================================================================================================================================================================================
MULTIPLE LINEAR REGRESSION

-WHEN MULTIPLE INDEPENDENT VARIABLES(PREDICTORS) ARE PRESENT	(DEPENDENT VARIABLES ARE TARGET VAR)
	-EXAMINE WHICH VARIABLES ARE SIGNIFICANT PREDICTORS OF THE OUTCOME VARIABLE
	-FIND OUT HOW EACH FEATURE IMPACTS THE OUTCOME VARIABLE
-METHOD OF PREDICTING A CONTINOUS VARIABLE
	-EXTENSION OF SIMPLE LINEAR REGRESSION

-INDEPENDENT VARIABLES EFFECTIVENESS ON PREDICTION
	-ID THE STRENGTH OF THE EFFECT THAT THE INDEPENDENT VARIABLES HAVE ON THE DEPENDENT VARIBLE
-PREDICTING IMPACTS OF CHANGES
	-HOW THE DEPENDENT VARIABLE CHANGES WHEN THE INDEPENDENT VARIABLE IS CHANGED

-ESTIMATING MULTIPLE LINEAR REGRESSION PARAMETERS
	-ORDINARY LEAST SQUARES: ESTIMATES THE VALUES OF THE COEFFICIENTS BY MINIMIZING THE MSE 
		TAKES TIME FOR LARGE DATASETS(+10K ROWS)
	-OPTIMIZATION ALGORITHM: OPTIMIZING VALUES OF THE COEFFICIENTS BY ITERATIVELY MINIMIZING THE 		ERROR OF THE MODEL ON YOUR TRAINING DATA
		-GRADIENT DESCENT: STARTS OPTIMIZING WITH RANDOM VALUES FOR EACH COEFFICIENT, THEN 			CALCULATES THE ERRORS AND TRIES TO MINIMIZE IT THRU Y'S CHANGING OF THE COEFFICIENT IN 		MULTIPLE ITERATIONS
			-PROPER FOR LARGE DATASETS
============================================================================================================================================================================================================
NON-LINEAR REGRESSION

-DATA REVEALS A CURVE/NOT TYPE LINEAR TREND

-POLYNOMIAL REGRESSION: FITS A CURVE LINE TO YOUR DATA
	-CAN BE TRANSFORMED INTO LINEAR REGRESSION MODEL
	-LEAST SQUARES: METHOD FOR ESTIMATING THE UNKNOWN PARAMETERS IN A LINEAR REGRESSION MODEL BY 	MINIMIZING THE SUM OF THE SQUARES OF THE DIFF BETWEEN OF THE OBSERVED DEPENDENT VARIABLE IN 	THE GIVEN DATA SET AND THOSE PREDICTED BY THE LINEAR FUNCTION

-NON LINEAR REGRESSION: A METHOD TO MODEL A NON-LINEAR RELATIONSHIP BETWEEN THE DEPENDENT VARIABLE AND A SET OF INDEPENDENT VARIABLES
	-A MODEL IS NON-LINEAR BY PARAMETERS
	-YHAT MUST BE A NON-LINEAR FUNCTION OF THE PARAMETER THETA, NOT NECESSARILY THE FEATURES x
	-CAN BE THE SHAPE OF EXPONENTIAL, LOGARITHMIC, LOGISTICAL, ETC

-THE CHANGE OF YHAT DEPENDS ON CHANGES IN THE PARAMETERS THETA, NOT NECESARILY ON X ONLY

-HOW CAN I KNOW IF THE PROBLEM IS LINEAR OR NON-LINEAR IN AN EASY WAY?
	-INSPECT VISUALLY 
	-CALCULATE CORRELATION COEFFICIENT BETWEEN IND VS DEP
	-IF 0.7 OR HIGHER, THERE IS A LINEAR TENDENCY
	-BASED ON ACCURACY 

-HOW SHOULD I MODEL MY DATA, IF IT DISPLAYS NON-LINEAR ON A SCATTER PLOT?
	-POLYNOMIAL/NON-LINEAR REGRESSION MODELS
	-TRANSFORM THE DATA